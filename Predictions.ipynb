{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import dill\n",
    "import dask_ml\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from importlib import reload\n",
    "from scipy import signal, stats\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import neighbors, linear_model, ensemble, decomposition #svm, neural_network\n",
    "from sklearn import feature_selection, model_selection, metrics, dummy, pipeline, preprocessing, compose\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from src import main, feature_model\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except NameError:\n",
    "    pass\n",
    "finally:\n",
    "    cluster = SLURMCluster(queue='short', cores=4, memory='8gb', walltime='1:00:00', death_timeout=60)\n",
    "    client = Client(cluster)\n",
    "    cluster.adapt(minimum=1, maximum=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'real_phone-tsfeatures'\n",
    "features_df = dd.read_parquet(f'/home/hy180/projects/beat_pd/extracted_features/{dataset}.parquet')\n",
    "\n",
    "label_cols = ['on_off', 'dyskinesia', 'tremor', 'subject_id']\n",
    "labels = pd.concat([\n",
    "    pd.read_csv('/home/hy180/projects/beat_pd/data/cis-pd/data_labels/CIS-PD_Training_Data_IDs_Labels.csv'),\n",
    "    pd.read_csv('/home/hy180/projects/beat_pd/data/real-pd/data_labels/REAL-PD_Training_Data_IDs_Labels.csv'),\n",
    "], axis=0).astype({'subject_id': str})\n",
    "\n",
    "# These features don't compute for a number of observations\n",
    "drop_cols = ['rms__friedrich_coefficients__m_3__r_30__coeff_0',\n",
    "       'rms__friedrich_coefficients__m_3__r_30__coeff_1',\n",
    "       'rms__friedrich_coefficients__m_3__r_30__coeff_2',\n",
    "       'rms__friedrich_coefficients__m_3__r_30__coeff_3',\n",
    "       'rms__max_langevin_fixed_point__m_3__r_30']\n",
    "# These fft features are null for our size of windows\n",
    "null_fft_cols = ['rms__fft_coefficient__coeff_%d__attr_\"%s\"' % (n, s) \n",
    "                     for n, s in product(range(51, 100), ['abs', 'angle', 'imag', 'real'])]\n",
    "# Sample entropy can take inf which screws with models\n",
    "inf_cols = ['rms__sample_entropy']\n",
    "df = features_df.drop(columns=[*drop_cols, *null_fft_cols, *inf_cols]).merge(labels, right_on='measurement_id', left_on='samp_id')\n",
    "# df = df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#pipeline"
    ]
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler(quantile_range=(1, 99))\n",
    "scaler_pg = {'scaler__quantile_range': [(.1, 99.9), (.5, 99.5), (1, 99), (5, 95), (10, 90)],}\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Keep features w/ variance in top 95%ile \n",
    "var = lambda X, y: np.var(X, axis=0)\n",
    "f_select = feature_selection.SelectPercentile(var, percentile=95)\n",
    "# f_select_pg = {'f_select__percentile': [95, 80, 50, 25, 10],}\n",
    "f_select_pg = {'f_select__percentile': stats.uniform(0, 100)}\n",
    "# f_select = feature_selection.SelectKBest(feature_selection.mutual_info_regression, k=30)\n",
    "\n",
    "# model = linear_model.Ridge()\n",
    "# model_pg = {'model__regressor__alpha': [0.1, 0.5, 1, 2, 5],}\n",
    "# model = svm.SVR()\n",
    "# model_pg = {'model__regressor__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'model__regressor__C': stats.chi2(df=2)}\n",
    "# model = linear_model.ElasticNet()\n",
    "# model_pg = {'model__regressor__l1_ratio': stats.uniform(0, 1), 'model__regressor__alpha': stats.chi2(df=2), }\n",
    "# model_pg = {'model__regressor__l1_ratio': [0.01, 0.1, 0.5, 0.8, 0.99], 'model__regressor__alpha': [0.1, 0.5, 1, 2, 5],}\n",
    "# model = mord.OrdinalRidge()\n",
    "# model_pg = {'model__regressor__alpha': stats.chi2(df=2), }\n",
    "model = ensemble.RandomForestRegressor()\n",
    "model_pg = {'model__regressor__n_estimators': stats.randint(3, 100), 'model__regressor__max_depth': stats.randint(2, 20), 'model__regressor__max_features': [.05, .25, 'auto', 'sqrt', 'log2']}\n",
    "# model = neural_network.MLPRegressor(learning_rate='adaptive')\n",
    "# model_pg = {'model__regressor__hidden_layer_sizes': [(100), (50, 50)]}\n",
    "\n",
    "clip_out = preprocessing.FunctionTransformer(np.clip, kw_args={'a_min': 0, 'a_max': 4})\n",
    "clipped_model = compose.TransformedTargetRegressor(regressor=model, inverse_func=clip_out.transform)\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('scaler', scaler), \n",
    "    ('f_select', f_select), \n",
    "    ('model', clipped_model),\n",
    "], verbose=1)\n",
    "\n",
    "param_grid = {\n",
    "    **scaler_pg,\n",
    "    **f_select_pg,\n",
    "    **model_pg,\n",
    "}\n",
    "\n",
    "metric = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv = model_selection.StratifiedKFold(shuffle=True)\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_iter=300, scoring=metric, cv=cv, refit=False, scheduler=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "#model-fit"
    ]
   },
   "outputs": [],
   "source": [
    "for label in ['on_off', 'dyskinesia', 'tremor']:\n",
    "    client.restart()\n",
    "    \n",
    "    id_cols = ['measurement_id', 'samp_id']\n",
    "    features = df.dropna(subset=[label]).drop(columns=[*label_cols, *id_cols])\n",
    "#     features = features.persist() \n",
    "\n",
    "    y = df.loc[features.index, label].astype('int')\n",
    "    X = features\n",
    "    \n",
    "    search = RandomizedSearchCV(pipe, param_grid, n_iter=300, scoring=metric, cv=cv, refit=False, scheduler=client)\n",
    "    cv_fit = search.fit(X, y)\n",
    "    cv_results = pd.DataFrame(cv_fit.cv_results_)\n",
    "\n",
    "    resultset_name = f'{dataset}_{type(model).__name__}_{label}'\n",
    "    cv_results.to_csv(f'performance/cv_paramsweeps/{resultset_name}.csv')\n",
    "    win_params = cv_results.loc[cv_results.rank_test_score == 1, 'params'].values[0]\n",
    "    winner = pipe.set_params(**win_params)\n",
    "    with open(f'models/paramsweep_winners/{resultset_name}.model', 'wb') as f:\n",
    "        dill.dump(winner, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single train-test split for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = ''\n",
    "with open(f'models/paramsweep_winners/RandomForestRegressor_{label}.model', 'rb') as f:\n",
    "    winner = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X.compute(), y.compute(), test_size=.25, stratify=y.compute())\n",
    "# x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "with joblib.parallel_backend('loky'):\n",
    "    winner.fit(x_train, y_train)\n",
    "    pred = winner.predict(x_test)\n",
    "\n",
    "main.plot_performance(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#data"
    ]
   },
   "outputs": [],
   "source": [
    "# label = 'dyskinesia'\n",
    "features = df.dropna(subset=[label]).drop(columns=[*label_cols, *id_cols])\n",
    "\n",
    "y = df.loc[features.index, label].astype('int').compute()\n",
    "metric = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_model = dummy.DummyRegressor(strategy='mean')\n",
    "# Pass in y for X because we don't actually care about X\n",
    "baseline_cv = model_selection.cross_validate(baseline_model, y, y, scoring=metric)\n",
    "baseline_scores = baseline_cv['test_score']\n",
    "ax = sns.countplot(y)\n",
    "ax.set_title('mse of null model: %f' % baseline_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# patient-specific mean predictor\n",
    "subj_means = labels.groupby('subject_id').mean()\n",
    "X_subjs = df.loc[X.index][['subject_id']]\n",
    "naive_pred = X_subjs.merge(subj_means[[label]], left_on='subject_id', right_index=True).rename(columns={label: 'prediction'})\n",
    "main.plot_performance(y, naive_pred.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'tremor'\n",
    "with open(f'models/paramsweep_winners/RandomForestRegressor_{label}.model', 'rb') as f:\n",
    "    winner = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: only predict required measurements for each label\n",
    "test_index = pd.read_csv(f'test_predictions/sub_template_{label}.csv', index_col=0).index\n",
    "test_features_df = pd.concat([\n",
    "    pd.read_csv('extracted_features/tsfeatures_cis_test.csv', index_col=0), \n",
    "    pd.read_csv('extracted_features/tsfeatures_real_test.csv', index_col=0)\n",
    "]).drop(columns=drop_cols).reindex(test_index)\n",
    "\n",
    "test_subjs = pd.concat([\n",
    "    pd.read_csv('data/test_set/cis-pd/cis-pd.CIS-PD_Test_Data_IDs.csv', index_col=0), \n",
    "    pd.read_csv('data/test_set/real-pd/real-pd.REAL-PD_Test_Data_IDs.csv', index_col=0)\n",
    "]).reindex(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict patient-specific mean if data not available\n",
    "nodata_obs = test_subjs.loc[test_features_df[test_features_df.isna().sum(axis=1) > 0].index]\n",
    "nodata_predictions = nodata_obs.join(subj_means, on='subject_id')[[label]].rename({label: 'prediction'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_features_df.dropna(axis='index')\n",
    "\n",
    "test_predictions = winner.predict(X)\n",
    "test_predictions_df = pd.concat([\n",
    "    pd.DataFrame(index=X.index, data={'prediction': test_predictions}),\n",
    "    nodata_predictions,\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df.to_csv(f'test_predictions/test_predictions_{label}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'subject_id'\n",
    "\n",
    "X = f_select.fit_transform(scaler.fit_transform(features), y=y)\n",
    "pca = decomposition.FastICA(n_components=2)\n",
    "proj = pca.fit_transform(X)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "_ = sns.scatterplot(x=proj[:, 0], y=proj[:, 1], hue=df.loc[features.index, label], legend='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster for debugging\n",
    "try:\n",
    "    local_cluster.close()\n",
    "    local_client.close()\n",
    "except NameError:\n",
    "    pass\n",
    "finally:\n",
    "    local_cluster = LocalCluster(n_workers=4, threads_per_worker=1, dashboard_address='0.0.0.0:8786')\n",
    "    local_client = Client(local_cluster)\n",
    "    local_cluster.adapt(minimum=0, maximum=4)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "170px",
    "left": "59px",
    "top": "241.133px",
    "width": "202px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
