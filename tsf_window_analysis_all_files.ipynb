{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from os.path import join\n",
    "import os\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_sum_cols(df):\n",
    "    sum_series = df.sum(axis=0)\n",
    "    nonzero_sum_cols = sum_series[sum_series > 0].index.values.tolist()\n",
    "    df = df[nonzero_sum_cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df):\n",
    "    return pd.DataFrame(\n",
    "        index=df.index.values.tolist(),\n",
    "        columns=df.columns.values.tolist(),\n",
    "        data=(df.values / df.values.sum(axis=0, keepdims=True))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "TSF_WINDOW_DIR = join(DATA_DIR, \"cis-pd\", \"training_data_tsf_sample\")\n",
    "TSF_WINDOW_FILES = [ join(TSF_WINDOW_DIR, f) for f in os.listdir(TSF_WINDOW_DIR) if f.endswith(\".tsf.csv\") ]\n",
    "LABELS_FILE = join(DATA_DIR, \"cis-pd\", \"data_labels\", \"CIS-PD_Training_Data_IDs_Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(LABELS_FILE, index_col=0)\n",
    "labels_df.head()\n",
    "\n",
    "m_ids = [ os.path.basename(f[:-8]) for f in TSF_WINDOW_FILES ]\n",
    "labels_df = labels_df.loc[m_ids,:]\n",
    "labels_df = labels_df.sort_values(by=\"on_off\", ascending=False)\n",
    "labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsense_variables = {\n",
    "    \"value__count_below__t_0\",\n",
    "    \"value__count_above__t_0\",\n",
    "    \"value__has_duplicate_min\",\n",
    "    \"value__has_duplicate_max\",\n",
    "    \"value__value_count__value_-1\",\n",
    "    \"value__value_count__value_0\",\n",
    "    \"value__value_count__value_1\",\n",
    "    \"value__number_crossing_m__m_-1\",\n",
    "    \"value__number_crossing_m__m_0\",\n",
    "    \"value__number_crossing_m__m_1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_variables(tsf_window_file):\n",
    "    f = tsf_window_file\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "    non_fft_cols = [ c for c in df.columns.values.tolist() if not c.startswith(\"value__fft\") ]\n",
    "    # Variance\n",
    "    var_df = pd.DataFrame(data=[], columns=[\"variable\", \"variance\", \"dim\"], index=[])\n",
    "    for dim, dim_df in df.groupby(\"id\"):\n",
    "        dim_df = dim_df.drop(columns=[\"id\", \"window_stop\", \"window_count\"])\n",
    "        dim_df = dim_df.set_index(\"window_start\", drop=True)\n",
    "        dim_df = remove_zero_sum_cols(dim_df)\n",
    "        dim_df = normalize_df(dim_df)\n",
    "\n",
    "        dim_var_df = dim_df.var().to_frame().reset_index().rename(columns={'index': 'variable', 0: 'variance'})\n",
    "        dim_var_df = dim_var_df.loc[dim_var_df[\"variable\"].isin(non_fft_cols)]\n",
    "        dim_var_df = dim_var_df.sort_values(by=\"variance\", ascending=False)\n",
    "        dim_var_df = dim_var_df.loc[dim_var_df[\"variance\"] <= 10]\n",
    "        dim_var_df = dim_var_df.loc[dim_var_df[\"variance\"] > 0.1]\n",
    "        dim_var_df[\"dim\"] = dim\n",
    "        var_df = var_df.append(dim_var_df, ignore_index=True)\n",
    "\n",
    "    var_variables = var_df[\"variable\"].unique().tolist()\n",
    "    \n",
    "    # Entropy\n",
    "    ent_df = pd.DataFrame(data=[], columns=[\"variable\", \"entropy\", \"dim\"], index=[])\n",
    "    for dim, dim_df in df.groupby(\"id\"):\n",
    "        dim_df = dim_df.drop(columns=[\"id\", \"window_stop\", \"window_count\"])\n",
    "        dim_df = dim_df.set_index(\"window_start\", drop=True)\n",
    "        dim_df = remove_zero_sum_cols(dim_df)\n",
    "        dim_entropies = []\n",
    "        for col_i, col_name in enumerate(dim_df.columns.values.tolist()):\n",
    "            dim_entropies.append({\n",
    "                \"variable\": col_name,\n",
    "                \"entropy\": scipy.stats.entropy(dim_df.values[:,col_i], base=2)\n",
    "            })\n",
    "        dim_ent_df = pd.DataFrame(data=dim_entropies)\n",
    "        dim_ent_df = dim_ent_df.loc[dim_ent_df[\"variable\"].isin(non_fft_cols)]\n",
    "        dim_ent_df = dim_ent_df.loc[dim_ent_df[\"entropy\"] <= 6]\n",
    "        dim_ent_df = dim_ent_df.loc[dim_ent_df[\"entropy\"] > 0]\n",
    "        dim_ent_df = dim_ent_df.sort_values(by=\"entropy\", ascending=False)\n",
    "        dim_ent_df[\"dim\"] = dim\n",
    "        ent_df = ent_df.append(dim_ent_df, ignore_index=True)\n",
    "\n",
    "    ent_variables = ent_df[\"variable\"].unique().tolist()\n",
    "    \n",
    "    intersect_variables = set(var_variables).union(set(ent_variables))\n",
    "    selected_variables = set(intersect_variables.difference(nonsense_variables))\n",
    "    return selected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_counts = {}\n",
    "for on_off_val in [0.0, 1.0, 2.0, 3.0, 4.0]:\n",
    "    var_counts[on_off_val] = {}\n",
    "    filtered_labels_df = labels_df.loc[labels_df[\"on_off\"] == on_off_val]\n",
    "    for m_id in filtered_labels_df.index.values.tolist():\n",
    "        f = join(TSF_WINDOW_DIR, f\"{m_id}.tsf.csv\")\n",
    "        f_vars = select_variables(f)\n",
    "    \n",
    "        for var_name in f_vars:\n",
    "            try:\n",
    "                var_counts[on_off_val][var_name] += 1\n",
    "            except KeyError:\n",
    "                var_counts[on_off_val][var_name] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_vars = set()\n",
    "percent_cutoff = 0.25\n",
    "for on_off_val in [0.0, 1.0, 2.0, 3.0, 4.0]:\n",
    "    filtered_labels_df = labels_df.loc[labels_df[\"on_off\"] == on_off_val]\n",
    "    num_obs = filtered_labels_df.shape[0]\n",
    "    num_top_obs = math.ceil(percent_cutoff * num_obs)\n",
    "    \n",
    "    var_val_counts = list(var_counts[on_off_val].items())\n",
    "    top_val_vars = set([ v[0] for v in var_val_counts if v[1] >= num_top_obs ])\n",
    "    top_vars = top_vars.union(top_val_vars)\n",
    "len(top_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from upsetplot import from_memberships\n",
    "#from upsetplot import UpSet\n",
    "#upset_data = from_memberships(all_vars, data=labels_df)\n",
    "#upset = UpSet(upset_data, intersection_plot_elements=2, orientation='vertical')\n",
    "#upset.add_catplot(value='on_off', kind='strip', color='blue')\n",
    "#upset.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"max\"__chunk_len_5__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"mean\"__chunk_len_10__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"mean\"__chunk_len_10__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"mean\"__chunk_len_50__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"mean\"__chunk_len_5__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"mean\"__chunk_len_5__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_10__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_10__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_50__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_50__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_5__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"min\"__chunk_len_5__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_10__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_10__attr_\"stderr\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_50__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_50__attr_\"stderr\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_5__attr_\"rvalue\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_5__attr_\"slope\"',\n",
       " 'value__agg_linear_trend__f_agg_\"var\"__chunk_len_5__attr_\"stderr\"',\n",
       " 'value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.6__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.2__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.6',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.6',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.2__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.0',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.2',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.4',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.6',\n",
       " 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8',\n",
       " 'value__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_0__w_10',\n",
       " 'value__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_0__w_2',\n",
       " 'value__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_10__w_2',\n",
       " 'value__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_14__w_2',\n",
       " 'value__large_standard_deviation__r_0.2',\n",
       " 'value__large_standard_deviation__r_0.25',\n",
       " 'value__large_standard_deviation__r_0.30000000000000004',\n",
       " 'value__large_standard_deviation__r_0.35000000000000003',\n",
       " 'value__large_standard_deviation__r_0.4',\n",
       " 'value__linear_trend__attr_\"pvalue\"',\n",
       " 'value__linear_trend__attr_\"rvalue\"',\n",
       " 'value__linear_trend__attr_\"slope\"',\n",
       " 'value__mean_change',\n",
       " 'value__mean_second_derivative_central',\n",
       " 'value__range_count__max_1000000000000.0__min_0',\n",
       " 'value__ratio_beyond_r_sigma__r_10',\n",
       " 'value__ratio_beyond_r_sigma__r_5',\n",
       " 'value__ratio_beyond_r_sigma__r_6',\n",
       " 'value__ratio_beyond_r_sigma__r_7',\n",
       " 'value__spkt_welch_density__coeff_2',\n",
       " 'value__spkt_welch_density__coeff_5',\n",
       " 'value__spkt_welch_density__coeff_8',\n",
       " 'value__time_reversal_asymmetry_statistic__lag_1',\n",
       " 'value__time_reversal_asymmetry_statistic__lag_2',\n",
       " 'value__time_reversal_asymmetry_statistic__lag_3',\n",
       " 'value__variance'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_DIR, \"tsf_window_variables.json\"), \"w\") as f:\n",
    "    json.dump(list(top_vars), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:beat-pd-mark-env] *",
   "language": "python",
   "name": "conda-env-beat-pd-mark-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
