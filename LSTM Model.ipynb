{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "As per yidi, need to work on deep learning part of the project. Gonna just try a quick shotgun approach to see what could work\n",
    "\n",
    "Supposedly would be nice to use the entire segment for LSTM, but lets just use 20 second segments for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from importlib import reload\n",
    "from sklearn import model_selection, metrics\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import signal\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "from src import main, feature_model\n",
    "\n",
    "labels1 = pd.read_csv('data/cis-pd/data_labels/CIS-PD_Training_Data_IDs_Labels.csv')\n",
    "labels2 = pd.read_csv('data/real-pd/data_labels/REAL-PD_Training_Data_IDs_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL-PD_Demographics.csv\n",
      "REAL-PD_Smartphone_Metadata.csv\n",
      "REAL-PD_UPDRS_Part1_2_4.csv\n",
      "REAL-PD_UPDRS_Part3.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ../beat_pd/data/real-pd/clinical_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets go and filter data with some utility funcs\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "\n",
    "# grabs some filter constants for making bandpass filter\n",
    "#    order is kinda like strength of filter... higher leads to more ideal filter but has weird interactions near the edges of the filter\n",
    "#    lower is less ideal but results in less artifacts being generated\n",
    "#    this is a bit of a cheat anyways, using a lowpass and highpass together, there may be less sketch filter designs applicable\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "def butter_lp_filter(data, lowcut, fs, order=5):\n",
    "    nyq = 0.5 * fs #just get the highest freq possible (nyquist, and bandgap it!)\n",
    "    hc = nyq * 0.9 #can't accept exactly nyq\n",
    "    print(\"hc:\", hc)\n",
    "    return butter_bandpass_filter(data, lowcut, hyc, fs, order)\n",
    "def butter_bandgap_filter(data, lowcut, highcut, fs, order=5):\n",
    "    if highcut is None:\n",
    "        return butter_bandgap_filter(data, lowcut, fs, order)\n",
    "    toRemove = butter_bandpass_filter(data, lowcut, highcut, fs, order)\n",
    "    return data - toRemove\n",
    "from src.main import read_seq\n",
    "\n",
    "def get_data(m_id):\n",
    "    data = pd.read_csv(f\"/home/ms994/beat_pd/data/cis-pd/training_data/{m_id}.csv\", index_col=\"Timestamp\", header=0)\n",
    "    return data.set_index(pd.to_timedelta(data.index, unit=\"s\"))\n",
    "def get_preprocessed_data(measurement_id, low_f=1, high_f=10):\n",
    "    data = get_data(measurement_id)\n",
    "    #50 hz, make a bandpass between 1 and 10 hz, with order of 5\n",
    "    data = butter_bandpass_filter(data, low_f, high_f, 50, 5)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try just using the frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "#from the EDA.ipynb\n",
    "np_x_data = pkl.load(open(\"/n/scratch2/ms994/beat_pd_frequency_data.pkl\", \"rb\"))\n",
    "y = pkl.load(open(\"/n/scratch2/ms994/beat_pd_labels_1s.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2210912, 3, 26), (2210912, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_x_data.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape back out into correct shape\n",
    "I flattened this between measurements originally as a way to run RF on everything, but running this as a sequence may make much more sense.\n",
    "The way I concatenated everything has maintained order, so I should be able to separate back out while keeping chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all the measurement ids\n",
    "m_ids = y.measurement_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ids.shape #only 963 in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedData = []\n",
    "for m_id in m_ids:\n",
    "    reshapedData.append(np_x_data[y.measurement_id==m_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1799"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshapedData[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try for 100 seconds of data with 50 second overlap\n",
    "time_reshaped_data = []\n",
    "time_reshaped_y = []\n",
    "for i, m_id in enumerate(m_ids):\n",
    "    max_instances = int(np.floor(reshapedData[i].shape[0]/50 - 1) )\n",
    "    for j in range(max_instances):\n",
    "        time_reshaped_data.append(reshapedData[i][j*50:j*50 + 100])\n",
    "        time_reshaped_y.append(label[label.measurement_id == m_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_reshaped_data = np.array(time_reshaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42707, 100, 3, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_reshaped_data.shape #lets try 1d cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like it is a correct pad value, nothing in the sequence matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import tensorflow as tf\n",
    "sys.path.append(os.path.realpath(\"/home/ms994/dbmi_eeg_clustering\")) #lol, i have a ton of utility classes here\n",
    "from keras_models.metrics import f1, sensitivity, specificity\n",
    "num_layers = 3\n",
    "num_lin_layers= 4\n",
    "inputX = tf.keras.layers.Input((100,3,26))\n",
    "x = tf.keras.layers.Reshape((100, 3*26))(inputX)\n",
    "for i in range(num_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(25, (3,))(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.CuDNNLSTM(20, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "# on off\n",
    "for i in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(200)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "x = tf.keras.layers.Dense(1, kernel_initializer='normal')(x)\n",
    "y_on_off = tf.keras.layers.ReLU(max_value=4)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputX], outputs=[y_on_off])\n",
    "model.compile(\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat(time_reshaped_y, axis=0)\n",
    "labels.head()\n",
    "y = labels.on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(labels.measurement_id.unique())\n",
    "# train, valid = train_test_split(labels.measurement_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = time_reshaped_data[labels.measurement_id.isin(train)]\n",
    "y_train = labels[labels.measurement_id.isin(train)]\n",
    "x_test = time_reshaped_data[labels.measurement_id.isin(test)]\n",
    "y_test = labels[labels.measurement_id.isin(test)]\n",
    "# x_valid = time_reshaped_data[labels.measurement_id.isin(valid)]\n",
    "# y_valid = labels[labels.measurement_id.isin(valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32041, 100, 3, 26)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100, 3, 26)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 100, 78)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 100, 78)           312       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 98, 25)            5875      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 98, 25)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 49, 25)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 49, 25)            100       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 47, 25)            1900      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 47, 25)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 23, 25)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 23, 25)            100       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 21, 25)            1900      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 21, 25)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 10, 25)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 25)            100       \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 10, 20)            3760      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 10, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 178,248\n",
      "Trainable params: 176,342\n",
      "Non-trainable params: 1,906\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25718 samples, validate on 6430 samples\n",
      "Epoch 1/1000\n",
      "25718/25718 [==============================] - 21s 801us/sample - loss: 2.0566 - val_loss: 1.1809\n",
      "Epoch 2/1000\n",
      "25718/25718 [==============================] - 15s 567us/sample - loss: 1.8811 - val_loss: 1.2784\n",
      "Epoch 3/1000\n",
      "25718/25718 [==============================] - 15s 570us/sample - loss: 1.8551 - val_loss: 0.9523\n",
      "Epoch 4/1000\n",
      "25718/25718 [==============================] - 15s 571us/sample - loss: 1.8163 - val_loss: 1.0835\n",
      "Epoch 5/1000\n",
      "25718/25718 [==============================] - 15s 570us/sample - loss: 1.8032 - val_loss: 1.2691\n",
      "Epoch 6/1000\n",
      "25718/25718 [==============================] - 15s 569us/sample - loss: 1.7783 - val_loss: 1.6500\n",
      "Epoch 7/1000\n",
      "25718/25718 [==============================] - 15s 570us/sample - loss: 1.7621 - val_loss: 1.3872\n",
      "Epoch 8/1000\n",
      "25718/25718 [==============================] - 15s 573us/sample - loss: 1.7407 - val_loss: 1.0696\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=y_train.on_off.astype(float).tolist(), validation_split=0.2, epochs=1000, callbacks=[tf.keras.callbacks.EarlyStopping(patience=5), tf.keras.callbacks.ModelCheckpoint(\"beat_pd.h5\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"beat_pd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10559/10559 [==============================] - 2s 223us/sample - loss: 1.8354\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(x_test, y_test.on_off.astype(float).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "y_test.loc[:,\"pred\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = y_test.groupby(\"measurement_id\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate.loc[:,\"mse\"] = (intermediate.on_off - intermediate.pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id\n",
       "1004    1.428571\n",
       "1007    1.041667\n",
       "1019    1.111111\n",
       "1023    2.266667\n",
       "1034    1.250000\n",
       "1038    0.816327\n",
       "1043    1.300000\n",
       "1048    1.692308\n",
       "1049    1.700000\n",
       "Name: on_off, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate.groupby(\"subject_id\")[\"on_off\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7cbefa2eb8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"Train On Off MSE\", \"Valid On Off MSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multioutput Neural Network\n",
    "Let's try to predict everything at once!\n",
    "\n",
    "Multiple weights could help regularize the network, but has the issue of trying to find the correct weighting to give each output. There have been a few methods to get around this, the most popular of which is https://arxiv.org/abs/1705.07115\n",
    "\n",
    "also, i've kinda always wanted to try this model out :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = pd.read_csv('data/cis-pd/data_labels/CIS-PD_Training_Data_IDs_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id\n",
       "1004     82\n",
       "1006     37\n",
       "1007    299\n",
       "1019     45\n",
       "1020    195\n",
       "1023    106\n",
       "1032    177\n",
       "1034     40\n",
       "1038    207\n",
       "1039    130\n",
       "1043     34\n",
       "1044     72\n",
       "1046     67\n",
       "1048     91\n",
       "1049     82\n",
       "1051    194\n",
       "Name: subject_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1.groupby(\"subject_id\")[\"subject_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_m_id = labels.measurement_id.unique()\n",
    "all_subject_id = labels.subject_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((963,), (9,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_m_id.shape, all_subject_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "class HomeoschedasticMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, loss_funcs=[],  **kwargs):\n",
    "        #multiplier is used to change signs\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.output_dim = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        self.multiplier = [1 for i in range(nb_outputs)]\n",
    "        self.loss_funcs = loss_funcs\n",
    "        super(HomeoschedasticMultiLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape=None):\n",
    "        # initialise log_vars\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            initializer=Constant(1)\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),\n",
    "                                              initializer=initializer, trainable=True)]\n",
    "        super(HomeoschedasticMultiLossLayer, self).build(input_shape)\n",
    "\n",
    "    def multi_loss(self, ys_true, ys_pred):\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        for i, zipped_args in enumerate(zip(ys_true, ys_pred, self.log_vars)):\n",
    "            y_true, y_pred, log_var = zipped_args\n",
    "            # normalized_log_var = log_var[0]/K.sum([other_log_var[0] for other_log_var in self.log_vars])\n",
    "\n",
    "            precision = K.exp(-log_var[0])\n",
    "            sign_cost = 1 if self.multiplier[i] > 0 else -1\n",
    "            if self.multiplier[i] == 0:\n",
    "                sign_cost = 0\n",
    "            loss += K.sum(precision * self.multiplier[i] * self.loss_funcs[i](y_true, y_pred)**2. + sign_cost * log_var[0], -1)\n",
    "        return K.mean(loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # pass thru the predictions\n",
    "        return K.concatenate(ys_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(labels.measurement_id)\n",
    "train, valid = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(m_id):\n",
    "    data = pd.read_csv(f\"/home/ms994/beat_pd/data/cis-pd/training_data/{m_id}.csv\", index_col=\"Timestamp\", header=0)\n",
    "    return data.set_index(pd.to_timedelta(data.index, unit=\"s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for m_id in train:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import tensorflow as tf\n",
    "sys.path.append(os.path.realpath(\"/home/ms994/dbmi_eeg_clustering\")) #lol, i have a ton of utility classes here\n",
    "from keras_models.metrics import f1, sensitivity, specificity\n",
    "num_layers = 2\n",
    "num_lin_layers= 4\n",
    "\n",
    "#shared encoder network\n",
    "inputX = tf.keras.layers.Input((100,50*20))\n",
    "x = tf.keras.layers.Reshape((100, 3*26))(inputX)\n",
    "for i in range(num_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(26*3, (3,))(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.CuDNNLSTM(50, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x_base = x  #last layer of the share network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = x_base\n",
    "# on off output\n",
    "for i in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(200)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "x = tf.keras.layers.Dense(1, kernel_initializer='normal')(x)\n",
    "y_on_off = tf.keras.layers.ReLU(max_value=4, name=\"on_off\")(x)\n",
    "\n",
    "\n",
    "# dyskinesia\n",
    "x = x_base\n",
    "for i in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(200)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "x = tf.keras.layers.Dense(1, kernel_initializer='normal')(x)\n",
    "y_dyskinesia = tf.keras.layers.ReLU(max_value=4, name=\"dyskinesia\")(x)\n",
    "\n",
    "\n",
    "#tremor\n",
    "x = x_base\n",
    "for i in range(num_lin_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(200)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "x = tf.keras.layers.Dense(1, kernel_initializer='normal')(x)\n",
    "y_tremor = tf.keras.layers.ReLU(max_value=4, name=\"tremor\")(x)\n",
    "\n",
    "\n",
    "#decoder network\n",
    "x = x_base\n",
    "for i in range(num_layers):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(26*3, (3,))(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(26*3, (3,))(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "\n",
    "\n",
    "# the size is off, the original is 100 by 26 by 3, we got 160, 23*3\n",
    "# x = tf.keras\n",
    "y_decoder_out = x\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputX], outputs=[y_on_off, y_dyskinesia, y_tremor, y_decoder_out])\n",
    "model.compile(\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 1000)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 78)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 100, 78)      312         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 98, 78)       18330       batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 98, 78)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 49, 78)       0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 49, 78)       312         max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 47, 78)       18330       batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 47, 78)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 23, 78)       0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 23, 78)       312         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 23, 50)       26000       time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 23, 50)       0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 23, 50)       200         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 23, 50)       200         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 23, 50)       200         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 23, 200)      10200       batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 23, 200)      10200       batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 23, 200)      10200       batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 23, 200)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 23, 200)      0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 23, 200)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 23, 200)      0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 23, 200)      0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 23, 200)      0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 23, 200)      800         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 23, 200)      800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 23, 200)      800         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 23, 200)      40200       batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 23, 200)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 23, 200)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 23, 200)      0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 23, 50)       200         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 23, 200)      0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 23, 200)      0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 23, 200)      0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 21, 78)       11778       batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 23, 200)      800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 23, 200)      800         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 23, 200)      800         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 21, 78)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 23, 200)      40200       batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 42, 78)       0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 23, 200)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 23, 200)      0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 23, 200)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 42, 78)       312         up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 23, 200)      0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 23, 200)      0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 23, 200)      0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 40, 78)       18330       batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 23, 200)      800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 23, 200)      800         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 23, 200)      800         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 40, 78)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 23, 200)      40200       batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 23, 200)      40200       batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 80, 78)       0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 23, 200)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 23, 200)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 23, 200)      0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 80, 78)       312         up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 23, 200)      0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 23, 200)      0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 23, 200)      0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 78, 78)       18330       batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 23, 1)        201         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 23, 1)        201         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 23, 1)        201         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 78, 78)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "on_off (ReLU)                   (None, 23, 1)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dyskinesia (ReLU)               (None, 23, 1)        0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tremor (ReLU)                   (None, 23, 1)        0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 156, 78)      0           leaky_re_lu_17[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 513,661\n",
      "Trainable params: 508,881\n",
      "Non-trainable params: 4,780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
