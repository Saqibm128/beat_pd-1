{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfresh as tsf\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from importlib import reload\n",
    "from datetime import timedelta\n",
    "from scipy import signal\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tsfresh.utilities.distribution import ClusterDaskDistributor\n",
    "from src import main, feature_model, extract_tsf_features_by_window as extract\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except NameError:\n",
    "    pass\n",
    "finally:\n",
    "#     Uncomment for SLURM execution\n",
    "#     cluster = SLURMCluster(queue='short', cores=2, memory='4gb', walltime='3:00:00', death_timeout=60)\n",
    "#     cluster.adapt(minimum=1, maximum=100)\n",
    "    cluster = LocalCluster()\n",
    "    cluster.adapt(minimum=1, maximum=3)\n",
    "    \n",
    "    client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55632</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>4.29 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55632' processes=1 threads=2, memory=4.29 GB>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_colnames = {'t_colname': 'Timestamp', 'xyz_colnames': ['X', 'Y', 'Z']}\n",
    "smartwatch_colnames = {'devid_colnames': ['device_id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsf_features(input_fp, \n",
    "                         window_offset=5, \n",
    "                         window_size=10, \n",
    "                         samp_rate='100ms',\n",
    "                         rms_g_constant=1,\n",
    "                         colnames=dict()):\n",
    "    seq = main.read_seq(input_fp, use_time_index=True, resample=samp_rate, **colnames)\n",
    "    # some slight interpolation for missing values\n",
    "    seq = seq.interpolate(axis=0, limit=1, method='linear')\n",
    "    \n",
    "    # subtract constant for gravity\n",
    "    rms = pd.DataFrame({'rms': np.sqrt(np.square(seq).sum(axis=1, skipna=False)) - rms_g_constant})\n",
    "    \n",
    "    window_starts = [pd.Timedelta(seconds=t) for t in [*range(0, rms.index.get_level_values('t').max().seconds - window_size, window_offset)]]\n",
    "    samples = main.sample_seq(rms, starts=window_starts, samp_len=pd.Timedelta(seconds=window_size), reset_time=True)\n",
    "    for i, df in enumerate(samples):\n",
    "        df['ord'] = str(i)\n",
    "        if 'devid_colnames' in colnames:\n",
    "            df.reset_index(level=colnames['devid_colnames'], inplace=True)\n",
    "            df['ord'] += '-' + df[colnames['devid_colnames'][0]]\n",
    "            df.drop(columns=colnames['devid_colnames'], inplace=True)\n",
    "    \n",
    "    # remove windows with nulls\n",
    "    tsf_data = pd.concat(samples, axis=0).groupby('ord').filter(lambda x: x.notnull().values.all())\n",
    "    \n",
    "    tsf_df = tsf.extract_features(tsf_data, column_id=\"ord\", disable_progressbar=True, n_jobs=0)\n",
    "    samp_id = os.path.splitext(os.path.basename(input_fp))[0]\n",
    "    tsf_df['samp_id'] = samp_id\n",
    "\n",
    "    return tsf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "window_offset = 5\n",
    "futures = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training data for cis_pd\n",
    "fps = glob.glob('data/cis-pd/training_data/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=1, \n",
    "                          colnames=cis_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/cis-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/cis-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_pd smartphone accelerometer\n",
    "fps = glob.glob('data/real-pd/training_data/smartphone_accelerometer/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=9.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/real_phone-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/real_phone-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_pd smartwatch accelerometer\n",
    "fps = glob.glob('data/real-pd/training_data/smartwatch_accelerometer/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=9.81, \n",
    "                          colnames=smartwatch_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/real_watch_accel-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/real_watch_accel-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_pd smartwatch gyroscope\n",
    "fps = glob.glob('data/real-pd/training_data/smartwatch_gyroscope/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=0, \n",
    "                          colnames=smartwatch_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/real_watch_gyro-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/real_watch_gyro-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for cis_pd\n",
    "fps = glob.glob('data/test_set/cis-pd/testing_data/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=1, \n",
    "                          colnames=cis_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/cis_test-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/cis_test-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_pd smartwatch accelerometer\n",
    "fps = glob.glob('data/test_set/real-pd/testing_data/smartwatch_accelerometer/*.csv')\n",
    "futures = client.map(extract_tsf_features, fps, \n",
    "                          window_size=window_size, \n",
    "                          window_offset=window_offset, \n",
    "                          rms_g_constant=9.81, \n",
    "                          colnames=smartwatch_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk directly since too much to store in mem\n",
    "iterator = as_completed(futures)\n",
    "future = next(iterator)\n",
    "while future.status == 'error': \n",
    "    future = next(iterator)\n",
    "result = future.result()\n",
    "result.to_csv('extracted_features/ensem/real_watch_accel_test-tsfeatures.csv', header=True)\n",
    "\n",
    "# Write remaining dfs in append mode \n",
    "for future in tqdm(iterator, total=len(futures)-1):\n",
    "    if future.status == 'finished':\n",
    "        result = future.result()\n",
    "        result.to_csv('extracted_features/ensem/real_watch_accel_test-tsfeatures.csv', header=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert csv files to parquet\n",
    "fps = glob.glob('extracted_features/ensem/*-tsfeatures.csv')\n",
    "for fp in fps:\n",
    "    df = pd.read_csv(fp)\n",
    "    df.to_parquet(fp[:-4] + '.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
