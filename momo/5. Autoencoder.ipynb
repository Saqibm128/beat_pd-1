{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.dataSetup.ipynb\n",
      "2.CNNLSTM.ipynb\n",
      "3. kerasOnlyExecution.ipynb\n",
      "4. Subject Specific Classification.ipynb\n",
      "5. Autoencoder.ipynb\n",
      "__pycache__\n",
      "history.pkl\n",
      "history3.pkl\n",
      "history4.pkl\n",
      "scratch.ipynb\n",
      "tf_mapper.py\n",
      "tfrecords.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import tf_mapper as tfm\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = { \\\n",
    "                'data':  tf.io.FixedLenFeature([1500*3], tf.float32,),\\\n",
    "                'on_off':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'dyskinesia':  tf.io.FixedLenFeature([1], tf.int64,),\n",
    "                'measurement_id':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'tremor':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                'age':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                \"subjects\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"gender\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartI_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartII_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.1\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.2\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.3\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.4\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.5\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.6\": tf.io.FixedLenFeature([1], tf.int64)\n",
    "               }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    return example\n",
    "def map_example_to_simple_with_mid(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, example['measurement_id']\n",
    "def tf_is_in_set(a, b):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(b, a), tf.int64)) >= 1\n",
    "#https://github.com/matthew-brett/transforms3d/blob/master/transforms3d/axangles.py\n",
    "def tfaxangle2mat(x, y, z, angle, is_normalized=False):\n",
    "#     x, y, z = axis\n",
    "    if not is_normalized:\n",
    "        n = tf.math.sqrt(x*x + y*y + z*z)\n",
    "        x = x/n\n",
    "        y = y/n\n",
    "        z = z/n\n",
    "    c = tf.math.cos(angle); s = tf.math.sin(angle); C = 1-c\n",
    "    xs = x*s;   ys = y*s;   zs = z*s\n",
    "    xC = x*C;   yC = y*C;   zC = z*C\n",
    "    xyC = x*yC; yzC = y*zC; zxC = z*xC\n",
    "    return tf.reshape(tf.concat([\n",
    "             x*xC+c,   xyC-zs,   zxC+ys ,\n",
    "             xyC+zs,   y*yC+c,   yzC-xs ,\n",
    "             zxC-ys,   yzC+xs,   z*zC+c ], axis=-1), (3,3))\n",
    "std = 1/4 #allow deviation from real rotation with pi/4 std\n",
    "def map_example_to_simple(example):\n",
    "    data = example[\"data\"]\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    update_matrix = tfaxangle2mat(tf.constant(0.0), tf.constant(0.0), tf.constant(1.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(0.0), tf.constant(1.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(1.0), tf.constant(0.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    data = data @ update_matrix\n",
    "    return data, data\n",
    "def get_batched_dataset(filenames, batch_size, m_ids, max_queue_size=10,  n_process=4, is_train=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=1, num_parallel_calls=1)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda example: tf_is_in_set(example[\"measurement_id\"][0], tf.constant(m_ids, dtype=tf.int64)))\n",
    "    dataset = dataset.filter(lambda example:  tf.math.logical_not(tf.reduce_any(tf.math.is_nan(example[\"data\"]))))\n",
    "    dataset = dataset.map(map_example_to_simple)\n",
    "    dataset = dataset.repeat()\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(2056)\n",
    "#     dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if is_train:\n",
    "        dataset = dataset.prefetch(max_queue_size)\n",
    "    else:\n",
    "        dataset = dataset.prefetch(int(max_queue_size/4)) #store a lot less for the other sets to avoid wasting memory\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tfm.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1858, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_mid, test_mid = train_test_split(labels.measurement_id.unique(), random_state=1)\n",
    "train_mid, valid_mid = train_test_split(train_mid, random_state=1)\n",
    "all_mid = sorted(labels.measurement_id)\n",
    "train_indices  = [all_mid.index(train_m) for train_m in train_mid]\n",
    "valid_indices  = [all_mid.index(train_m) for train_m in valid_mid]\n",
    "test_indices  = [all_mid.index(train_m) for train_m in test_mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=256)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNo (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1500, 3)           30        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 750, 3)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 750, 3)            12        \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 750, 5)            50        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 750, 5)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 375, 5)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 375, 5)            20        \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_16 (CuDNNLSTM)    (None, 375, 4)            176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 375, 4)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 375, 4)            16        \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_17 (CuDNNLSTM)    (None, 375, 2)            64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 640)               480640    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 640)               2560      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 320)               205120    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 320)               1280      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 160)               51360     \n",
      "_________________________________________________________________\n",
      "encoder_output (LeakyReLU)   (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 320)               51520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 320)               1280      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 750)               240750    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_18 (CuDNNLSTM)    (None, 375, 1)            20        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 375, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 375, 1)            4         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_19 (CuDNNLSTM)    (None, 375, 2)            40        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 375, 5)            35        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 375, 5)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1 (None, 750, 5)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 750, 5)            20        \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 750, 3)            48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 750, 3)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1 (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1500, 3)           12        \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1500, 3)           30        \n",
      "=================================================================\n",
      "Total params: 1,062,151\n",
      "Trainable params: 1,058,897\n",
      "Non-trainable params: 3,254\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_cnn_layers = 2\n",
    "num_lstm_layers = 2\n",
    "dropout = 0.5\n",
    "lin_h=16*40\n",
    "lstm_h = 4\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(2*(i+1)+1, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(int(lstm_h/(2**j)), return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x_shape = x.shape\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h/2)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h/4)(x)\n",
    "x = tf.keras.layers.LeakyReLU(name=\"encoder_output\")(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h/4)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h/2)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(x_shape[1].value * x_shape[2].value)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Reshape((x_shape[1].value, x_shape[2].value))(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(int(lstm_h/(2**(num_lstm_layers-j))), return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(2*num_cnn_layers-2*(i)+1, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(3, (3,), padding=\"same\")(x)\n",
    "model = tf.keras.models.Model(inputs=inputLayer, outputs=x)\n",
    "model.summary()\n",
    "model.compile(\"adam\", loss=\"logcosh\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-9.6213407e-05, -1.8305256e-04, -9.4585028e-04],\n",
       "        [ 3.7469716e-05,  3.9976966e-04, -2.1422752e-03],\n",
       "        [ 2.2183784e-04,  4.4619126e-04, -2.7612848e-03],\n",
       "        ...,\n",
       "        [-1.5470010e-04, -1.9955179e-03, -1.6932752e-03],\n",
       "        [-8.7287772e-04, -1.6650428e-03, -2.7994625e-04],\n",
       "        [ 3.4059914e-05, -1.9781585e-04, -5.8310950e-05]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.random.random((1,1500,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = None, None\n",
    "with tf.Session() as sess:\n",
    "    x, y = train_data.take(10).make_one_shot_iterator().get_next()\n",
    "    y = y.eval()\n",
    "    x = x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "500/500 [==============================] - 106s 213ms/step - loss: 0.0967 - mean_squared_error: 0.2182 - val_loss: 0.0840 - val_mean_squared_error: 0.1830\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 88s 175ms/step - loss: 0.0714 - mean_squared_error: 0.1558 - val_loss: 0.0744 - val_mean_squared_error: 0.1622\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0647 - mean_squared_error: 0.1406 - val_loss: 0.0645 - val_mean_squared_error: 0.1395\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 0.0641 - mean_squared_error: 0.1392 - val_loss: 0.0622 - val_mean_squared_error: 0.1347\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 88s 175ms/step - loss: 0.0588 - mean_squared_error: 0.1274 - val_loss: 0.0578 - val_mean_squared_error: 0.1243\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0584 - mean_squared_error: 0.1264 - val_loss: 0.0564 - val_mean_squared_error: 0.1215\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0567 - mean_squared_error: 0.1225 - val_loss: 0.0564 - val_mean_squared_error: 0.1215\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0576 - mean_squared_error: 0.1247 - val_loss: 0.0590 - val_mean_squared_error: 0.1275\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0566 - mean_squared_error: 0.1225 - val_loss: 0.0577 - val_mean_squared_error: 0.1243\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0554 - mean_squared_error: 0.1196 - val_loss: 0.0537 - val_mean_squared_error: 0.1155\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 88s 177ms/step - loss: 0.0543 - mean_squared_error: 0.1171 - val_loss: 0.0530 - val_mean_squared_error: 0.1139\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0538 - mean_squared_error: 0.1160 - val_loss: 0.0580 - val_mean_squared_error: 0.1246\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 0.0530 - mean_squared_error: 0.1143 - val_loss: 0.0515 - val_mean_squared_error: 0.1104\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0520 - mean_squared_error: 0.1122 - val_loss: 0.0534 - val_mean_squared_error: 0.1145\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0483 - mean_squared_error: 0.1041 - val_loss: 0.0487 - val_mean_squared_error: 0.1049\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 88s 177ms/step - loss: 0.0451 - mean_squared_error: 0.0975 - val_loss: 0.0448 - val_mean_squared_error: 0.0967\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 0.0419 - mean_squared_error: 0.0905 - val_loss: 0.0408 - val_mean_squared_error: 0.0879\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 0.0384 - mean_squared_error: 0.0830 - val_loss: 0.0394 - val_mean_squared_error: 0.0848\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0358 - mean_squared_error: 0.0774 - val_loss: 0.0366 - val_mean_squared_error: 0.0785\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 88s 176ms/step - loss: 0.0351 - mean_squared_error: 0.0757 - val_loss: 0.0331 - val_mean_squared_error: 0.0713\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0338 - mean_squared_error: 0.0730 - val_loss: 0.0335 - val_mean_squared_error: 0.0719\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 84s 169ms/step - loss: 0.0332 - mean_squared_error: 0.0716 - val_loss: 0.0319 - val_mean_squared_error: 0.0685\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 0.0322 - mean_squared_error: 0.0696 - val_loss: 0.0333 - val_mean_squared_error: 0.0717\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0313 - mean_squared_error: 0.0676 - val_loss: 0.0298 - val_mean_squared_error: 0.0640\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0297 - mean_squared_error: 0.0643 - val_loss: 0.0311 - val_mean_squared_error: 0.0669\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0288 - mean_squared_error: 0.0623 - val_loss: 0.0274 - val_mean_squared_error: 0.0589\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0284 - mean_squared_error: 0.0614 - val_loss: 0.0286 - val_mean_squared_error: 0.0611\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 0.0280 - mean_squared_error: 0.0607 - val_loss: 0.0276 - val_mean_squared_error: 0.0593\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0279 - mean_squared_error: 0.0605 - val_loss: 0.0319 - val_mean_squared_error: 0.0683\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 0.0273 - mean_squared_error: 0.0593 - val_loss: 0.0275 - val_mean_squared_error: 0.0588\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0267 - mean_squared_error: 0.0577 - val_loss: 0.0250 - val_mean_squared_error: 0.0539\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0270 - mean_squared_error: 0.0584 - val_loss: 0.0251 - val_mean_squared_error: 0.0539\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0259 - mean_squared_error: 0.0559 - val_loss: 0.0242 - val_mean_squared_error: 0.0520\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0256 - mean_squared_error: 0.0553 - val_loss: 0.0250 - val_mean_squared_error: 0.0537\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0246 - mean_squared_error: 0.0532 - val_loss: 0.0240 - val_mean_squared_error: 0.0516\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0244 - mean_squared_error: 0.0528 - val_loss: 0.0232 - val_mean_squared_error: 0.0497\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0240 - mean_squared_error: 0.0520 - val_loss: 0.0244 - val_mean_squared_error: 0.0524\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0243 - mean_squared_error: 0.0524 - val_loss: 0.0232 - val_mean_squared_error: 0.0498\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0238 - mean_squared_error: 0.0515 - val_loss: 0.0242 - val_mean_squared_error: 0.0518\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0235 - mean_squared_error: 0.0507 - val_loss: 0.0230 - val_mean_squared_error: 0.0493\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0233 - mean_squared_error: 0.0505 - val_loss: 0.0239 - val_mean_squared_error: 0.0512\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0232 - mean_squared_error: 0.0502 - val_loss: 0.0227 - val_mean_squared_error: 0.0487\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0233 - mean_squared_error: 0.0502 - val_loss: 0.0248 - val_mean_squared_error: 0.0530\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0229 - mean_squared_error: 0.0495 - val_loss: 0.0222 - val_mean_squared_error: 0.0475\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0229 - mean_squared_error: 0.0494 - val_loss: 0.0218 - val_mean_squared_error: 0.0467\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0228 - mean_squared_error: 0.0493 - val_loss: 0.0215 - val_mean_squared_error: 0.0461\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0228 - mean_squared_error: 0.0493 - val_loss: 0.0223 - val_mean_squared_error: 0.0478\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0225 - mean_squared_error: 0.0487 - val_loss: 0.0217 - val_mean_squared_error: 0.0465\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0225 - mean_squared_error: 0.0487 - val_loss: 0.0211 - val_mean_squared_error: 0.0454\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0222 - mean_squared_error: 0.0479 - val_loss: 0.0223 - val_mean_squared_error: 0.0479\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0221 - mean_squared_error: 0.0477 - val_loss: 0.0216 - val_mean_squared_error: 0.0464\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0221 - mean_squared_error: 0.0478 - val_loss: 0.0213 - val_mean_squared_error: 0.0457\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0220 - mean_squared_error: 0.0476 - val_loss: 0.0207 - val_mean_squared_error: 0.0446\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0223 - mean_squared_error: 0.0481 - val_loss: 0.0212 - val_mean_squared_error: 0.0454\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0219 - mean_squared_error: 0.0475 - val_loss: 0.0218 - val_mean_squared_error: 0.0467\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0220 - mean_squared_error: 0.0475 - val_loss: 0.0230 - val_mean_squared_error: 0.0491\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0215 - mean_squared_error: 0.0466 - val_loss: 0.0216 - val_mean_squared_error: 0.0462\n",
      "Epoch 58/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0216 - mean_squared_error: 0.0466 - val_loss: 0.0215 - val_mean_squared_error: 0.0460\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0217 - mean_squared_error: 0.0470 - val_loss: 0.0217 - val_mean_squared_error: 0.0466\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0216 - mean_squared_error: 0.0466 - val_loss: 0.0203 - val_mean_squared_error: 0.0436\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0217 - mean_squared_error: 0.0468 - val_loss: 0.0237 - val_mean_squared_error: 0.0506\n",
      "Epoch 62/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0215 - mean_squared_error: 0.0466 - val_loss: 0.0202 - val_mean_squared_error: 0.0433\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0213 - mean_squared_error: 0.0460 - val_loss: 0.0219 - val_mean_squared_error: 0.0470\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0210 - mean_squared_error: 0.0454 - val_loss: 0.0251 - val_mean_squared_error: 0.0534\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0214 - mean_squared_error: 0.0461 - val_loss: 0.0211 - val_mean_squared_error: 0.0452\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0209 - mean_squared_error: 0.0451 - val_loss: 0.0208 - val_mean_squared_error: 0.0446\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0208 - mean_squared_error: 0.0451 - val_loss: 0.0211 - val_mean_squared_error: 0.0452\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0211 - mean_squared_error: 0.0456 - val_loss: 0.0228 - val_mean_squared_error: 0.0486\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0207 - mean_squared_error: 0.0449 - val_loss: 0.0201 - val_mean_squared_error: 0.0431\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0203 - mean_squared_error: 0.0439 - val_loss: 0.0196 - val_mean_squared_error: 0.0420\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0201 - mean_squared_error: 0.0437 - val_loss: 0.0209 - val_mean_squared_error: 0.0448\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0198 - mean_squared_error: 0.0428 - val_loss: 0.0193 - val_mean_squared_error: 0.0415\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0195 - mean_squared_error: 0.0421 - val_loss: 0.0188 - val_mean_squared_error: 0.0403\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0194 - mean_squared_error: 0.0421 - val_loss: 0.0188 - val_mean_squared_error: 0.0404\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0194 - mean_squared_error: 0.0420 - val_loss: 0.0194 - val_mean_squared_error: 0.0415\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0191 - mean_squared_error: 0.0414 - val_loss: 0.0184 - val_mean_squared_error: 0.0395\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0190 - mean_squared_error: 0.0412 - val_loss: 0.0188 - val_mean_squared_error: 0.0404\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0190 - mean_squared_error: 0.0412 - val_loss: 0.0195 - val_mean_squared_error: 0.0418\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0191 - mean_squared_error: 0.0413 - val_loss: 0.0181 - val_mean_squared_error: 0.0389\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0190 - mean_squared_error: 0.0411 - val_loss: 0.0181 - val_mean_squared_error: 0.0388\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0187 - mean_squared_error: 0.0404 - val_loss: 0.0173 - val_mean_squared_error: 0.0373\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0188 - mean_squared_error: 0.0406 - val_loss: 0.0179 - val_mean_squared_error: 0.0383\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0186 - mean_squared_error: 0.0402 - val_loss: 0.0177 - val_mean_squared_error: 0.0380\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0188 - mean_squared_error: 0.0406 - val_loss: 0.0179 - val_mean_squared_error: 0.0384\n",
      "Epoch 85/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0190 - mean_squared_error: 0.0412 - val_loss: 0.0197 - val_mean_squared_error: 0.0421\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0189 - mean_squared_error: 0.0409 - val_loss: 0.0181 - val_mean_squared_error: 0.0389\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0187 - mean_squared_error: 0.0407 - val_loss: 0.0176 - val_mean_squared_error: 0.0379\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0186 - mean_squared_error: 0.0401 - val_loss: 0.0174 - val_mean_squared_error: 0.0374\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0184 - mean_squared_error: 0.0397 - val_loss: 0.0174 - val_mean_squared_error: 0.0375\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0183 - mean_squared_error: 0.0397 - val_loss: 0.0173 - val_mean_squared_error: 0.0371\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0184 - mean_squared_error: 0.0398 - val_loss: 0.0184 - val_mean_squared_error: 0.0393\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0183 - mean_squared_error: 0.0396 - val_loss: 0.0173 - val_mean_squared_error: 0.0372\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0182 - mean_squared_error: 0.0394 - val_loss: 0.0175 - val_mean_squared_error: 0.0377\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0181 - mean_squared_error: 0.0392 - val_loss: 0.0176 - val_mean_squared_error: 0.0377\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0183 - mean_squared_error: 0.0395 - val_loss: 0.0219 - val_mean_squared_error: 0.0470\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0187 - mean_squared_error: 0.0404 - val_loss: 0.0189 - val_mean_squared_error: 0.0406\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0184 - mean_squared_error: 0.0398 - val_loss: 0.0171 - val_mean_squared_error: 0.0366\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0181 - mean_squared_error: 0.0392 - val_loss: 0.0173 - val_mean_squared_error: 0.0373\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0180 - mean_squared_error: 0.0389 - val_loss: 0.0178 - val_mean_squared_error: 0.0382\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0180 - mean_squared_error: 0.0389 - val_loss: 0.0171 - val_mean_squared_error: 0.0367\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0179 - mean_squared_error: 0.0388 - val_loss: 0.0178 - val_mean_squared_error: 0.0382\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 88s 175ms/step - loss: 0.0180 - mean_squared_error: 0.0390 - val_loss: 0.0170 - val_mean_squared_error: 0.0365\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0181 - mean_squared_error: 0.0393 - val_loss: 0.0176 - val_mean_squared_error: 0.0378\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0180 - mean_squared_error: 0.0390 - val_loss: 0.0165 - val_mean_squared_error: 0.0354\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0178 - mean_squared_error: 0.0386 - val_loss: 0.0174 - val_mean_squared_error: 0.0374\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0178 - mean_squared_error: 0.0386 - val_loss: 0.0181 - val_mean_squared_error: 0.0387\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0178 - mean_squared_error: 0.0386 - val_loss: 0.0166 - val_mean_squared_error: 0.0356\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0176 - mean_squared_error: 0.0381 - val_loss: 0.0240 - val_mean_squared_error: 0.0510\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0178 - mean_squared_error: 0.0386 - val_loss: 0.0164 - val_mean_squared_error: 0.0352\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0175 - mean_squared_error: 0.0381 - val_loss: 0.0174 - val_mean_squared_error: 0.0373\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 85s 170ms/step - loss: 0.0177 - mean_squared_error: 0.0383 - val_loss: 0.0173 - val_mean_squared_error: 0.0371\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0178 - mean_squared_error: 0.0386 - val_loss: 0.0167 - val_mean_squared_error: 0.0358\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0176 - mean_squared_error: 0.0381 - val_loss: 0.0170 - val_mean_squared_error: 0.0365\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0181 - mean_squared_error: 0.0392 - val_loss: 0.0462 - val_mean_squared_error: 0.0980\n",
      "Epoch 115/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0194 - mean_squared_error: 0.0421 - val_loss: 0.0213 - val_mean_squared_error: 0.0455\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0184 - mean_squared_error: 0.0397 - val_loss: 0.0177 - val_mean_squared_error: 0.0380\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0180 - mean_squared_error: 0.0391 - val_loss: 0.0167 - val_mean_squared_error: 0.0360\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0180 - mean_squared_error: 0.0390 - val_loss: 0.0164 - val_mean_squared_error: 0.0353\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0176 - mean_squared_error: 0.0382 - val_loss: 0.0167 - val_mean_squared_error: 0.0359\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0176 - mean_squared_error: 0.0381 - val_loss: 0.0164 - val_mean_squared_error: 0.0353\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0175 - mean_squared_error: 0.0379 - val_loss: 0.0164 - val_mean_squared_error: 0.0353\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0174 - mean_squared_error: 0.0378 - val_loss: 0.0168 - val_mean_squared_error: 0.0360\n",
      "Epoch 123/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0174 - mean_squared_error: 0.0377 - val_loss: 0.0165 - val_mean_squared_error: 0.0355\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0173 - mean_squared_error: 0.0376 - val_loss: 0.0161 - val_mean_squared_error: 0.0347\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0173 - mean_squared_error: 0.0376 - val_loss: 0.0164 - val_mean_squared_error: 0.0351\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0172 - mean_squared_error: 0.0373 - val_loss: 0.0163 - val_mean_squared_error: 0.0350\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0172 - mean_squared_error: 0.0372 - val_loss: 0.0161 - val_mean_squared_error: 0.0347\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0176 - mean_squared_error: 0.0381 - val_loss: 0.0163 - val_mean_squared_error: 0.0350\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0174 - mean_squared_error: 0.0376 - val_loss: 0.0177 - val_mean_squared_error: 0.0379\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0172 - mean_squared_error: 0.0373 - val_loss: 0.0188 - val_mean_squared_error: 0.0402\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0171 - mean_squared_error: 0.0372 - val_loss: 0.0168 - val_mean_squared_error: 0.0361\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0174 - mean_squared_error: 0.0376 - val_loss: 0.0176 - val_mean_squared_error: 0.0377\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0172 - mean_squared_error: 0.0373 - val_loss: 0.0162 - val_mean_squared_error: 0.0348\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0172 - mean_squared_error: 0.0373 - val_loss: 0.0158 - val_mean_squared_error: 0.0339\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0171 - mean_squared_error: 0.0371 - val_loss: 0.0171 - val_mean_squared_error: 0.0368\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0170 - mean_squared_error: 0.0368 - val_loss: 0.0160 - val_mean_squared_error: 0.0344\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0170 - mean_squared_error: 0.0369 - val_loss: 0.0170 - val_mean_squared_error: 0.0364\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0169 - mean_squared_error: 0.0366 - val_loss: 0.0171 - val_mean_squared_error: 0.0366\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0169 - mean_squared_error: 0.0365 - val_loss: 0.0164 - val_mean_squared_error: 0.0351\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0169 - mean_squared_error: 0.0366 - val_loss: 0.0155 - val_mean_squared_error: 0.0333\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0169 - mean_squared_error: 0.0367 - val_loss: 0.0161 - val_mean_squared_error: 0.0345\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0168 - mean_squared_error: 0.0364 - val_loss: 0.0164 - val_mean_squared_error: 0.0352\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0170 - mean_squared_error: 0.0368 - val_loss: 0.0173 - val_mean_squared_error: 0.0370\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0169 - mean_squared_error: 0.0367 - val_loss: 0.0163 - val_mean_squared_error: 0.0350\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0170 - mean_squared_error: 0.0369 - val_loss: 0.0159 - val_mean_squared_error: 0.0342\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0168 - mean_squared_error: 0.0364 - val_loss: 0.0172 - val_mean_squared_error: 0.0368\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0167 - mean_squared_error: 0.0363 - val_loss: 0.0156 - val_mean_squared_error: 0.0336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0168 - mean_squared_error: 0.0364 - val_loss: 0.0157 - val_mean_squared_error: 0.0337\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0166 - mean_squared_error: 0.0360 - val_loss: 0.0154 - val_mean_squared_error: 0.0331\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0173 - mean_squared_error: 0.0374 - val_loss: 0.0171 - val_mean_squared_error: 0.0366\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0170 - mean_squared_error: 0.0369 - val_loss: 0.0169 - val_mean_squared_error: 0.0362\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0169 - mean_squared_error: 0.0366 - val_loss: 0.0157 - val_mean_squared_error: 0.0336\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0169 - mean_squared_error: 0.0366 - val_loss: 0.0155 - val_mean_squared_error: 0.0334\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0167 - mean_squared_error: 0.0363 - val_loss: 0.0156 - val_mean_squared_error: 0.0336\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0167 - mean_squared_error: 0.0362 - val_loss: 0.0158 - val_mean_squared_error: 0.0340\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0167 - mean_squared_error: 0.0363 - val_loss: 0.0154 - val_mean_squared_error: 0.0331\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0167 - mean_squared_error: 0.0363 - val_loss: 0.0160 - val_mean_squared_error: 0.0342\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0168 - mean_squared_error: 0.0365 - val_loss: 0.0181 - val_mean_squared_error: 0.0386\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0168 - mean_squared_error: 0.0363 - val_loss: 0.0154 - val_mean_squared_error: 0.0331\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0167 - mean_squared_error: 0.0361 - val_loss: 0.0163 - val_mean_squared_error: 0.0350\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0167 - mean_squared_error: 0.0361 - val_loss: 0.0176 - val_mean_squared_error: 0.0377\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0167 - mean_squared_error: 0.0361 - val_loss: 0.0157 - val_mean_squared_error: 0.0336\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0166 - mean_squared_error: 0.0360 - val_loss: 0.0165 - val_mean_squared_error: 0.0352\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0166 - mean_squared_error: 0.0359 - val_loss: 0.0158 - val_mean_squared_error: 0.0340\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0166 - mean_squared_error: 0.0360 - val_loss: 0.0157 - val_mean_squared_error: 0.0337\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0165 - mean_squared_error: 0.0358 - val_loss: 0.0161 - val_mean_squared_error: 0.0346\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0164 - mean_squared_error: 0.0356 - val_loss: 0.0152 - val_mean_squared_error: 0.0326\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0163 - mean_squared_error: 0.0354 - val_loss: 0.0152 - val_mean_squared_error: 0.0326\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0163 - mean_squared_error: 0.0354 - val_loss: 0.0157 - val_mean_squared_error: 0.0337\n",
      "Epoch 170/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0162 - mean_squared_error: 0.0352 - val_loss: 0.0155 - val_mean_squared_error: 0.0334\n",
      "Epoch 171/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0163 - mean_squared_error: 0.0354 - val_loss: 0.0164 - val_mean_squared_error: 0.0351\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0162 - mean_squared_error: 0.0352 - val_loss: 0.0191 - val_mean_squared_error: 0.0408\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0164 - mean_squared_error: 0.0355 - val_loss: 0.0169 - val_mean_squared_error: 0.0362\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0163 - mean_squared_error: 0.0354 - val_loss: 0.0159 - val_mean_squared_error: 0.0342\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0163 - mean_squared_error: 0.0353 - val_loss: 0.0154 - val_mean_squared_error: 0.0332\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0162 - mean_squared_error: 0.0351 - val_loss: 0.0155 - val_mean_squared_error: 0.0333\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0163 - mean_squared_error: 0.0354 - val_loss: 0.0164 - val_mean_squared_error: 0.0351\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0163 - mean_squared_error: 0.0353 - val_loss: 0.0183 - val_mean_squared_error: 0.0390\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0162 - mean_squared_error: 0.0351 - val_loss: 0.0153 - val_mean_squared_error: 0.0329\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0163 - mean_squared_error: 0.0353 - val_loss: 0.0180 - val_mean_squared_error: 0.0384\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0165 - mean_squared_error: 0.0357 - val_loss: 0.0160 - val_mean_squared_error: 0.0344\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0163 - mean_squared_error: 0.0353 - val_loss: 0.0162 - val_mean_squared_error: 0.0348\n",
      "Epoch 183/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0161 - mean_squared_error: 0.0351 - val_loss: 0.0147 - val_mean_squared_error: 0.0315\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0162 - mean_squared_error: 0.0352 - val_loss: 0.0151 - val_mean_squared_error: 0.0326\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 87s 175ms/step - loss: 0.0161 - mean_squared_error: 0.0349 - val_loss: 0.0148 - val_mean_squared_error: 0.0320\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0162 - mean_squared_error: 0.0351 - val_loss: 0.0148 - val_mean_squared_error: 0.0318\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0161 - mean_squared_error: 0.0349 - val_loss: 0.0148 - val_mean_squared_error: 0.0318\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0160 - mean_squared_error: 0.0348 - val_loss: 0.0164 - val_mean_squared_error: 0.0351\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0162 - mean_squared_error: 0.0352 - val_loss: 0.0147 - val_mean_squared_error: 0.0315\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0162 - mean_squared_error: 0.0351 - val_loss: 0.0160 - val_mean_squared_error: 0.0344\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 87s 174ms/step - loss: 0.0161 - mean_squared_error: 0.0348 - val_loss: 0.0159 - val_mean_squared_error: 0.0341\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0161 - mean_squared_error: 0.0349 - val_loss: 0.0147 - val_mean_squared_error: 0.0316\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 84s 169ms/step - loss: 0.0161 - mean_squared_error: 0.0350 - val_loss: 0.0164 - val_mean_squared_error: 0.0353\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 85s 171ms/step - loss: 0.0161 - mean_squared_error: 0.0349 - val_loss: 0.0149 - val_mean_squared_error: 0.0320\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0162 - mean_squared_error: 0.0351 - val_loss: 0.0166 - val_mean_squared_error: 0.0355\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0159 - mean_squared_error: 0.0345 - val_loss: 0.0144 - val_mean_squared_error: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0159 - mean_squared_error: 0.0345 - val_loss: 0.0158 - val_mean_squared_error: 0.0338\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 86s 171ms/step - loss: 0.0159 - mean_squared_error: 0.0344 - val_loss: 0.0147 - val_mean_squared_error: 0.0315\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0159 - mean_squared_error: 0.0344 - val_loss: 0.0146 - val_mean_squared_error: 0.0315\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 87s 173ms/step - loss: 0.0161 - mean_squared_error: 0.0348 - val_loss: 0.0151 - val_mean_squared_error: 0.0325\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20, verbose=True)\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/autoEncoderCISPD.h5\", save_best_only=True)\n",
    "history = model.fit(train_data, steps_per_epoch=500, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[earlyStopping, modelCheckpoint],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
