{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.dataSetup.ipynb\n",
      "2.CNNLSTM.ipynb\n",
      "3. kerasOnlyExecution.ipynb\n",
      "4. Subject Specific Classification.ipynb\n",
      "5. Autoencoder.ipynb\n",
      "__pycache__\n",
      "history.pkl\n",
      "history3.pkl\n",
      "history4.pkl\n",
      "scratch.ipynb\n",
      "tf_mapper.py\n",
      "tfrecords.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import tf_mapper as tfm\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = { \\\n",
    "                'data':  tf.io.FixedLenFeature([1500*3], tf.float32,),\\\n",
    "                'on_off':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'dyskinesia':  tf.io.FixedLenFeature([1], tf.int64,),\n",
    "                'measurement_id':  tf.io.FixedLenFeature([1], tf.int64,),\\\n",
    "                'tremor':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                'age':  tf.io.FixedLenFeature([1], tf.int64,), \\\n",
    "                \"subjects\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"gender\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartI_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_PartII_Total\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.1\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.2\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.3\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.4\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.5\": tf.io.FixedLenFeature([1], tf.int64), \\\n",
    "                \"UPDRS_4.6\": tf.io.FixedLenFeature([1], tf.int64)\n",
    "               }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    return example\n",
    "def map_example_to_simple_with_mid(example):\n",
    "    data = example['data']\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    return data, example['measurement_id']\n",
    "def tf_is_in_set(a, b):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(b, a), tf.int64)) >= 1\n",
    "#https://github.com/matthew-brett/transforms3d/blob/master/transforms3d/axangles.py\n",
    "def tfaxangle2mat(x, y, z, angle, is_normalized=False):\n",
    "#     x, y, z = axis\n",
    "    if not is_normalized:\n",
    "        n = tf.math.sqrt(x*x + y*y + z*z)\n",
    "        x = x/n\n",
    "        y = y/n\n",
    "        z = z/n\n",
    "    c = tf.math.cos(angle); s = tf.math.sin(angle); C = 1-c\n",
    "    xs = x*s;   ys = y*s;   zs = z*s\n",
    "    xC = x*C;   yC = y*C;   zC = z*C\n",
    "    xyC = x*yC; yzC = y*zC; zxC = z*xC\n",
    "    return tf.reshape(tf.concat([\n",
    "             x*xC+c,   xyC-zs,   zxC+ys ,\n",
    "             xyC+zs,   y*yC+c,   yzC-xs ,\n",
    "             zxC-ys,   yzC+xs,   z*zC+c ], axis=-1), (3,3))\n",
    "std = 1/4 #allow deviation from real rotation with pi/4 std\n",
    "def map_example_to_simple(example):\n",
    "    data = example[\"data\"]\n",
    "    data = tf.reshape(data, (1500,3))\n",
    "    update_matrix = tfaxangle2mat(tf.constant(0.0), tf.constant(0.0), tf.constant(1.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(0.0), tf.constant(1.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    update_matrix = update_matrix @ tfaxangle2mat(tf.constant(1.0), tf.constant(0.0), tf.constant(0.0), tf.random.normal((1,)) * tf.constant(3.14*std))\n",
    "    data = data @ update_matrix\n",
    "    return data, data\n",
    "def get_batched_dataset(filenames, batch_size, m_ids, max_queue_size=10,  n_process=4, is_train=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=1, num_parallel_calls=1)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=n_process)\n",
    "    dataset = dataset.filter(lambda example: tf_is_in_set(example[\"measurement_id\"][0], tf.constant(m_ids, dtype=tf.int64)))\n",
    "    dataset = dataset.filter(lambda example:  tf.math.logical_not(tf.reduce_any(tf.math.is_nan(example[\"data\"]))))\n",
    "    dataset = dataset.map(map_example_to_simple)\n",
    "    dataset = dataset.repeat()\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(2056)\n",
    "#     dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if is_train:\n",
    "        dataset = dataset.prefetch(max_queue_size)\n",
    "    else:\n",
    "        dataset = dataset.prefetch(int(max_queue_size/4)) #store a lot less for the other sets to avoid wasting memory\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tfm.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1858, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_mid, test_mid = train_test_split(labels.measurement_id.unique(), random_state=1)\n",
    "train_mid, valid_mid = train_test_split(train_mid, random_state=1)\n",
    "all_mid = sorted(labels.measurement_id)\n",
    "train_indices  = [all_mid.index(train_m) for train_m in train_mid]\n",
    "valid_indices  = [all_mid.index(train_m) for train_m in valid_mid]\n",
    "test_indices  = [all_mid.index(train_m) for train_m in test_mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=train_indices, batch_size=128)\n",
    "valid_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=valid_indices, batch_size=256)\n",
    "test_data = get_batched_dataset(\"/n/scratch2/beat_pd_ms_tmp/all_data.tfr\", m_ids=test_indices, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1500, 3)           30        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 750, 3)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 750, 3)            12        \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 750, 5)            50        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 750, 5)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 375, 5)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 375, 5)            20        \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 375, 4)            176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 375, 4)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 375, 4)            16        \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 375, 2)            64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 640)               480640    \n",
      "_________________________________________________________________\n",
      "encoder_output (LeakyReLU)   (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 640)               2560      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 750)               480750    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 750)               3000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 375)               281625    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 375)               1500      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 0)                 0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 0)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 0)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 375)               375       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 375, 1)            20        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 375, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 375, 1)            4         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 375, 2)            40        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 375, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 375, 2)            8         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 375, 5)            35        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 375, 5)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 750, 5)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 750, 5)            20        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 750, 3)            48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 750, 3)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 1500, 3)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 1500, 3)           12        \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1500, 3)           30        \n",
      "=================================================================\n",
      "Total params: 1,251,051\n",
      "Trainable params: 1,247,467\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_cnn_layers = 2\n",
    "num_lstm_layers = 2\n",
    "dropout = 0.5\n",
    "lin_h=16*40\n",
    "lstm_h = 4\n",
    "inputLayer = tf.keras.layers.Input((1500, 3))\n",
    "x = inputLayer\n",
    "x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "\n",
    "\n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(2*(i+1)+1, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPool1D((2,))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(int(lstm_h/(2**j)), return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x_shape = x.shape\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(lin_h)(x)\n",
    "x = tf.keras.layers.LeakyReLU(name=\"encoder_output\")(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(x_shape[1].value * x_shape[2].value)(x)\n",
    "x = tf.keras.layers.LeakyReLU()(x)\n",
    "x = tf.keras.layers.Reshape((x_shape[1].value, x_shape[2].value))(x)\n",
    "\n",
    "for j in range(num_lstm_layers):\n",
    "    x = tf.keras.layers.CuDNNLSTM(int(lstm_h/(2**(num_lstm_layers-j))), return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "for i in range(num_cnn_layers):\n",
    "    x = tf.keras.layers.Conv1D(2*num_cnn_layers-2*(i)+1, (3,), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(3, (3,), padding=\"same\")(x)\n",
    "model = tf.keras.models.Model(inputs=inputLayer, outputs=x)\n",
    "model.summary()\n",
    "model.compile(\"adam\", loss=\"logcosh\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.random.random((1,1500,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = None, None\n",
    "with tf.Session() as sess:\n",
    "    x, y = train_data.take(10).make_one_shot_iterator().get_next()\n",
    "    y = y.eval()\n",
    "    x = x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 370s 370ms/step - loss: 0.1271 - mean_squared_error: 0.7651 - val_loss: 0.0773 - val_mean_squared_error: 0.1680\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.0640 - mean_squared_error: 0.1391 - val_loss: 0.0771 - val_mean_squared_error: 0.1714\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 362s 362ms/step - loss: 0.0413 - mean_squared_error: 0.0894 - val_loss: 0.0338 - val_mean_squared_error: 0.0725\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.0315 - mean_squared_error: 0.0679 - val_loss: 0.0294 - val_mean_squared_error: 0.0628\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.0283 - mean_squared_error: 0.0610 - val_loss: 0.0288 - val_mean_squared_error: 0.0615\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.0268 - mean_squared_error: 0.0578 - val_loss: 0.0253 - val_mean_squared_error: 0.0541\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.0262 - mean_squared_error: 0.0565 - val_loss: 0.0273 - val_mean_squared_error: 0.0582\n",
      "Epoch 8/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0540"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-93137d8efeda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearlyStopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodelCheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/n/scratch2/ms994/autoEncoderCISPD.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelCheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m           validation_in_fit=True)\n\u001b[0m\u001b[1;32m    365\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0;31m# `ins` can be callable in DistributionStrategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=20, verbose=True)\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/n/scratch2/ms994/autoEncoderCISPD.h5\", save_best_only=True)\n",
    "history = model.fit(train_data, steps_per_epoch=1000, epochs=200, validation_data=valid_data, validation_steps=100, callbacks=[earlyStopping, modelCheckpoint],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
